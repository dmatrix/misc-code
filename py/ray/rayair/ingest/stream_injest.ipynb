{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dae906fb-4957-4a07-b095-0e0d9e350bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import ray\n",
    "from ray.air import session, Checkpoint\n",
    "from ray.data import DatasetPipeline\n",
    "from ray.train.torch import TorchTrainer\n",
    "from ray.air.config import DatasetConfig\n",
    "from ingest_utils import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff9a68e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.8.13</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 3.0.0.dev0</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://127.0.0.1:8266\" target=\"_blank\">http://127.0.0.1:8266</a></b></td>\n",
       "</tr>\n",
       "\n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='127.0.0.1:8266', python_version='3.8.13', ray_version='3.0.0.dev0', ray_commit='{{RAY_COMMIT_SHA}}', address_info={'node_ip_address': '127.0.0.1', 'raylet_ip_address': '127.0.0.1', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2022-08-02_13-12-27_684894_67427/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-08-02_13-12-27_684894_67427/sockets/raylet', 'webui_url': '127.0.0.1:8266', 'session_dir': '/tmp/ray/session_2022-08-02_13-12-27_684894_67427', 'metrics_export_port': 60654, 'gcs_address': '127.0.0.1:62921', 'address': '127.0.0.1:62921', 'dashboard_agent_listen_port': 52365, 'node_id': '506b6bd50a4064f5c557d5e5420c545e039cf8cbedc1925818adddde'})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "if ray.is_initialized:\n",
    "    ray.shutdown()\n",
    "ray.init(logging_level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12e4be80-8751-4d7c-82f3-ca63c962d0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model(batch):\n",
    "#     return len(batch) * 0.1 * random.uniform(0,1)\n",
    "\n",
    "def train_loop_per_worker():\n",
    "    # A DatasetPipeline object is returned when `use_stream_api` is set.\n",
    "    data_shard: DatasetPipeline = session.get_dataset_shard(\"train\")\n",
    "    \n",
    "    acc = 0.0\n",
    "    # Manually iterate over the data 10 times (10 epochs).\n",
    "    for epoch in data_shard.iter_epochs(10): \n",
    "        # for each epoch iterate over batches\n",
    "        num_batches = 0\n",
    "        num_epochs = 0\n",
    "        for batch in epoch.iter_batches():\n",
    "            num_batches += 1\n",
    "            num_epochs += 1\n",
    "            batch_acc = model(batch)\n",
    "            acc += batch_acc\n",
    "        acc /= num_batches * 100\n",
    "        if num_epochs % 2 == 0:\n",
    "            print(f\"Doing some training on epoch: {num_epochs} for batches: {num_batches} and loss over batch: {acc:.3f}\")\n",
    "        session.report({\"acc\": acc, \"epoch\": num_epochs}, \n",
    "                       checkpoint=Checkpoint.from_dict({\"acc\": acc, \"epoch\": num_epochs}))\n",
    "    # View the stats for performance debugging.\n",
    "    # print(data_shard.stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91efb78c-a84c-4a06-9f8a-2df24af4a659",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.air.config import ScalingConfig\n",
    "\n",
    "# Set N = 200 bytes for this toy example. Typically, you'd set N >= 1GiB.\n",
    "N = 200\n",
    "train_ds = ray.data.range_tensor(1000)\n",
    "trainer = TorchTrainer(train_loop_per_worker,\n",
    "                       scaling_config= ScalingConfig(num_workers=1),\n",
    "                       datasets={\"train\": train_ds},\n",
    "                       dataset_config={\"train\": DatasetConfig(use_stream_api=True, \n",
    "                                                              stream_window_size=N)},\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ecf150e-b6ec-441f-8739-72941e792af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-08-02 13:12:51 (running for 00:00:06.11)<br>Memory usage on this node: 18.7/64.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/10 CPUs, 0/0 GPUs, 0.0/40.59 GiB heap, 0.0/2.0 GiB objects<br>Result logdir: /Users/jules/ray_results/TorchTrainer_2022-08-02_13-12-45<br>Number of trials: 1/1 (1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     acc</th><th style=\"text-align: right;\">  epoch</th><th style=\"text-align: right;\">  _timestamp</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_78b74_00000</td><td>TERMINATED</td><td>127.0.0.1:72216</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         4.12106</td><td style=\"text-align: right;\">0.428409</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">  1659471170</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=72226)\u001b[0m 2022-08-02 13:12:47,689\tINFO config.py:71 -- Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=72216)\u001b[0m 2022-08-02 13:12:47,908\tINFO dataset.py:3233 -- Created DatasetPipeline with 20 windows: 400b min, 400b max, 400b mean\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=72216)\u001b[0m 2022-08-02 13:12:47,909\tINFO dataset.py:3243 -- Blocks per window: 1 min, 1 max, 1 mean\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=72216)\u001b[0m 2022-08-02 13:12:47,910\tWARNING dataset.py:3255 -- ⚠️  This pipeline's parallelism is limited by its blocks per window to ~1 concurrent tasks per window. To maximize performance, increase the blocks per window to at least 4. This may require increasing the base dataset's parallelism and/or adjusting the windowing parameters.\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=72216)\u001b[0m 2022-08-02 13:12:47,911\tINFO dataset.py:3282 -- ✔️  This pipeline's windows likely fit in object store memory without spilling.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=72226)\u001b[0m [W ProcessGroupGloo.cpp:715] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\n",
      "Stage 0:   0%|          | 0/1 [00:00<?, ?it/s]=72238)\u001b[0m \n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[Aor pid=72238)\u001b[0m \n",
      "Stage 1:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A238)\u001b[0m \n",
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=72238)\u001b[0m \n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[Apid=72238)\u001b[0m \n",
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=72238)\u001b[0m \n",
      "Stage 2:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A)\u001b[0m \n",
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=72238)\u001b[0m \n",
      "Stage 0: : 2it [00:00,  2.10it/s]             .05it/s]\u001b[A \n",
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=72238)\u001b[0m \n",
      "Stage 2: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\u001b[A\u001b[A\n",
      "Stage 0: : 20it [00:01, 25.27it/s]                    \u001b[A \n",
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=72238)\u001b[0m \n",
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=72238)\u001b[0m \n",
      "Stage 2: : 19it [00:01, 24.29it/s]                    \u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for TorchTrainer_78b74_00000:\n",
      "  _time_this_iter_s: 1.9532630443572998\n",
      "  _timestamp: 1659471169\n",
      "  _training_iteration: 1\n",
      "  acc: 0.42307759752536983\n",
      "  date: 2022-08-02_13-12-49\n",
      "  done: false\n",
      "  epoch: 4\n",
      "  experiment_id: 97a222b531324fbe8cbfb98433261bf1\n",
      "  hostname: Juless-MacBook-Pro-16\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 72216\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 3.291666030883789\n",
      "  time_this_iter_s: 3.291666030883789\n",
      "  time_total_s: 3.291666030883789\n",
      "  timestamp: 1659471169\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 78b74_00000\n",
      "  warmup_time: 0.0033578872680664062\n",
      "  \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=72226)\u001b[0m Doing some training on epoch: 4 for batches: 4 and loss over batch: 0.423\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=72226)\u001b[0m Doing some training on epoch: 4 for batches: 4 and loss over batch: 0.434\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=72226)\u001b[0m Doing some training on epoch: 4 for batches: 4 and loss over batch: 0.412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=72238)\u001b[0m \n",
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=72238)\u001b[0m \n",
      "Stage 2: : 43it [00:01, 54.90it/s]\u001b[A\u001b[Aor pid=72238)\u001b[0m \n",
      "Stage 0: : 45it [00:01, 56.96it/s]\u001b[Anator pid=72238)\u001b[0m \n",
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=72238)\u001b[0m \n",
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=72238)\u001b[0m \n",
      "Stage 2: : 63it [00:01, 79.64it/s]\u001b[A\u001b[Aor pid=72238)\u001b[0m \n",
      "Stage 0: : 65it [00:01, 81.28it/s]\u001b[Anator pid=72238)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=72226)\u001b[0m Doing some training on epoch: 4 for batches: 4 and loss over batch: 0.410\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=72226)\u001b[0m Doing some training on epoch: 4 for batches: 4 and loss over batch: 0.417\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=72226)\u001b[0m Doing some training on epoch: 4 for batches: 4 and loss over batch: 0.421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=72238)\u001b[0m \n",
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=72238)\u001b[0m \n",
      "Stage 2: : 83it [00:01, 101.31it/s]\u001b[A\u001b[Ar pid=72238)\u001b[0m \n",
      "Stage 0: : 85it [00:01, 102.56it/s]\u001b[Aator pid=72238)\u001b[0m \n",
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=72238)\u001b[0m \n",
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=72238)\u001b[0m \n",
      "Stage 2: : 105it [00:01, 126.49it/s]\u001b[A\u001b[A pid=72238)\u001b[0m \n",
      "Stage 0: : 107it [00:01, 127.43it/s]\u001b[Ator pid=72238)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=72226)\u001b[0m Doing some training on epoch: 4 for batches: 4 and loss over batch: 0.413\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=72226)\u001b[0m Doing some training on epoch: 4 for batches: 4 and loss over batch: 0.419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=72238)\u001b[0m \n",
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=72238)\u001b[0m \n",
      "Stage 2: : 132it [00:01, 160.26it/s]\u001b[A\u001b[A pid=72238)\u001b[0m \n",
      "Stage 0: : 134it [00:01, 160.95it/s]\u001b[Ator pid=72238)\u001b[0m \n",
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=72238)\u001b[0m \n",
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=72238)\u001b[0m \n",
      "Stage 2: : 159it [00:01, 187.65it/s]\u001b[A\u001b[A pid=72238)\u001b[0m \n",
      "Stage 0: : 161it [00:01, 188.14it/s]\u001b[Ator pid=72238)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=72226)\u001b[0m Doing some training on epoch: 4 for batches: 4 and loss over batch: 0.418\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=72226)\u001b[0m Doing some training on epoch: 4 for batches: 4 and loss over batch: 0.428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=72238)\u001b[0m \n",
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=72238)\u001b[0m \n",
      "Stage 2: : 183it [00:01, 185.79it/s]\u001b[A\u001b[A pid=72238)\u001b[0m \n",
      "Stage 0: : 185it [00:01, 186.12it/s]\u001b[Ator pid=72238)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for TorchTrainer_78b74_00000:\n",
      "  _time_this_iter_s: 0.0832369327545166\n",
      "  _timestamp: 1659471170\n",
      "  _training_iteration: 10\n",
      "  acc: 0.42840909908721947\n",
      "  date: 2022-08-02_13-12-50\n",
      "  done: true\n",
      "  epoch: 4\n",
      "  experiment_id: 97a222b531324fbe8cbfb98433261bf1\n",
      "  experiment_tag: '0'\n",
      "  hostname: Juless-MacBook-Pro-16\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 72216\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 4.121056079864502\n",
      "  time_this_iter_s: 0.09208011627197266\n",
      "  time_total_s: 4.121056079864502\n",
      "  timestamp: 1659471170\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 10\n",
      "  trial_id: 78b74_00000\n",
      "  warmup_time: 0.0033578872680664062\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=72238)\u001b[0m /opt/miniconda3/envs/ray-build/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n",
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=72238)\u001b[0m   warnings.warn('resource_tracker: There appear to be %d '\n"
     ]
    }
   ],
   "source": [
    "result = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e205d5a-6030-45f9-bf5a-4473c2343764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result(metrics={'acc': 0.42840909908721947, 'epoch': 4, '_timestamp': 1659471170, '_time_this_iter_s': 0.0832369327545166, '_training_iteration': 10, 'should_checkpoint': True, 'done': True, 'trial_id': '78b74_00000', 'experiment_tag': '0'}, error=None, log_dir=PosixPath('/Users/jules/ray_results/TorchTrainer_2022-08-02_13-12-45/TorchTrainer_78b74_00000_0_2022-08-02_13-12-45'))\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a8b6ff5-1991-45de-ab59-c38d68226fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5941ea3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "0f9baa705f095037670b11d47114911b546aeb3e0a8b56407edb208eea715d47"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
