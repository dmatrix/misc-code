{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dae906fb-4957-4a07-b095-0e0d9e350bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import ray\n",
    "from ray.air import session, Checkpoint\n",
    "from ray.data import DatasetPipeline\n",
    "from ray.train.torch import TorchTrainer\n",
    "from ray.air.config import DatasetConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12e4be80-8751-4d7c-82f3-ca63c962d0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(batch):\n",
    "    return len(batch) * 0.1 * random.uniform(0,1)\n",
    "\n",
    "def train_loop_per_worker():\n",
    "    # A DatasetPipeline object is returned when `use_stream_api` is set.\n",
    "    data_shard: DatasetPipeline = session.get_dataset_shard(\"train\")\n",
    "    \n",
    "    loss = 0.0\n",
    "    # Manually iterate over the data 10 times (10 epochs).\n",
    "    for epoch in data_shard.iter_epochs(10): \n",
    "        # for each epoch iterate over batches\n",
    "        num_batches = 0\n",
    "        num_epochs = 0\n",
    "        for batch in epoch.iter_batches():\n",
    "            num_batches += 1\n",
    "            num_epochs += 1\n",
    "            batch_loss = model(batch)\n",
    "            loss += batch_loss\n",
    "        loss /= num_batches * 100\n",
    "        if num_epochs % 2 == 0:\n",
    "            print(f\"Doing some training on epoch: {num_epochs} for batches: {num_batches} and loss over batch: {loss:.3f}\")\n",
    "        session.report({\"loss\": loss, \"epoch\": num_epochs}, \n",
    "                       checkpoint=Checkpoint.from_dict({\"loss\": loss, \"epoch\": num_epochs}))\n",
    "    # View the stats for performance debugging.\n",
    "    # print(data_shard.stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91efb78c-a84c-4a06-9f8a-2df24af4a659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set N = 200 bytes for this toy example. Typically, you'd set N >= 1GiB.\n",
    "N = 200\n",
    "train_ds = ray.data.range_tensor(1000)\n",
    "trainer = TorchTrainer(train_loop_per_worker,\n",
    "                       scaling_config={\"num_workers\": 1},\n",
    "                       datasets={\"train\": train_ds},\n",
    "                       dataset_config={\"train\": DatasetConfig(use_stream_api=True, \n",
    "                                                              stream_window_size=N)},\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ecf150e-b6ec-441f-8739-72941e792af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-07-16 15:12:06 (running for 00:00:04.75)<br>Memory usage on this node: 20.5/64.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/10 CPUs, 0/0 GPUs, 0.0/38.41 GiB heap, 0.0/2.0 GiB objects<br>Result logdir: /Users/jules/ray_results/TorchTrainer_2022-07-16_15-12-02<br>Number of trials: 1/1 (1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  epoch</th><th style=\"text-align: right;\">  _timestamp</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_518ce_00000</td><td>TERMINATED</td><td>127.0.0.1:86187</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         2.87596</td><td style=\"text-align: right;\">0.0255333</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">  1658009526</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TorchTrainer pid=86187)\u001b[0m 2022-07-16 15:12:04,275\tINFO dataset.py:3094 -- Created DatasetPipeline with 20 windows: 400b min, 400b max, 400b mean\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=86187)\u001b[0m 2022-07-16 15:12:04,276\tINFO dataset.py:3103 -- Blocks per window: 1 min, 1 max, 1 mean\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m 2022-07-16 15:12:04,258\tINFO config.py:70 -- Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m [W ProcessGroupGloo.cpp:715] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\n",
      "Stage 0:   0%|          | 0/1 [00:00<?, ?it/s]=86197)\u001b[0m \n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[Aor pid=86197)\u001b[0m \n",
      "Stage 1:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A197)\u001b[0m \n",
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=86197)\u001b[0m \n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[Apid=86197)\u001b[0m \n",
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=86197)\u001b[0m \n",
      "Stage 2:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A)\u001b[0m \n",
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=86197)\u001b[0m \n",
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=86197)\u001b[0m \n",
      "Stage 2: : 10it [00:00, 98.65it/s]            \u001b[A\u001b[A)\u001b[0m \n",
      "Stage 0: : 12it [00:00, 117.86it/s]           \u001b[A197)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m Doing some training on epoch: 20 for batches: 20 and loss over batch: 0.030\n",
      "Result for TorchTrainer_518ce_00000:\n",
      "  _time_this_iter_s: 0.8639390468597412\n",
      "  _timestamp: 1658009525\n",
      "  _training_iteration: 1\n",
      "  date: 2022-07-16_15-12-05\n",
      "  done: false\n",
      "  epoch: 20\n",
      "  experiment_id: 858e3fea072f4687a81dde9582592f9f\n",
      "  hostname: Juless-MacBook-Pro-16\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.029737603763258125\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 86187\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 1.8201608657836914\n",
      "  time_this_iter_s: 1.8201608657836914\n",
      "  time_total_s: 1.8201608657836914\n",
      "  timestamp: 1658009525\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 518ce_00000\n",
      "  warmup_time: 0.0030679702758789062\n",
      "  \n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m Doing some training on epoch: 20 for batches: 20 and loss over batch: 0.029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=86197)\u001b[0m \n",
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=86197)\u001b[0m \n",
      "Stage 2: : 30it [00:00, 156.58it/s]\u001b[A\u001b[Ar pid=86197)\u001b[0m \n",
      "Stage 0: : 32it [00:00, 164.41it/s]\u001b[Aator pid=86197)\u001b[0m \n",
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=86197)\u001b[0m \n",
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=86197)\u001b[0m \n",
      "Stage 2: : 46it [00:00, 126.08it/s]\u001b[A\u001b[Ar pid=86197)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m Doing some training on epoch: 20 for batches: 20 and loss over batch: 0.024\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m Doing some training on epoch: 20 for batches: 20 and loss over batch: 0.026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=86197)\u001b[0m \n",
      "Stage 0: : 49it [00:00, 110.74it/s]\u001b[Aator pid=86197)\u001b[0m \n",
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=86197)\u001b[0m \n",
      "Stage 2: : 60it [00:00, 122.47it/s]\u001b[A\u001b[Ar pid=86197)\u001b[0m \n",
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=86197)\u001b[0m \n",
      "Stage 0: : 65it [00:00, 121.47it/s]\u001b[Aator pid=86197)\u001b[0m \n",
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=86197)\u001b[0m \n",
      "Stage 2: : 79it [00:00, 143.45it/s]\u001b[A\u001b[Ar pid=86197)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m Doing some training on epoch: 20 for batches: 20 and loss over batch: 0.023\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m Doing some training on epoch: 20 for batches: 20 and loss over batch: 0.021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=86197)\u001b[0m \n",
      "Stage 0: : 85it [00:00, 143.27it/s]\u001b[Aator pid=86197)\u001b[0m \n",
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=86197)\u001b[0m \n",
      "Stage 2: : 99it [00:00, 160.34it/s]\u001b[A\u001b[Ar pid=86197)\u001b[0m \n",
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=86197)\u001b[0m \n",
      "Stage 0: : 105it [00:00, 159.33it/s]\u001b[Ator pid=86197)\u001b[0m \n",
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=86197)\u001b[0m \n",
      "Stage 2: : 119it [00:00, 171.18it/s]\u001b[A\u001b[A pid=86197)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m Doing some training on epoch: 20 for batches: 20 and loss over batch: 0.026\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m Doing some training on epoch: 20 for batches: 20 and loss over batch: 0.028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=86197)\u001b[0m \n",
      "Stage 0: : 125it [00:00, 170.07it/s]\u001b[Ator pid=86197)\u001b[0m \n",
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=86197)\u001b[0m \n",
      "Stage 2: : 139it [00:00, 178.54it/s]\u001b[A\u001b[A pid=86197)\u001b[0m \n",
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=86197)\u001b[0m \n",
      "Stage 0: : 145it [00:00, 177.51it/s]\u001b[Ator pid=86197)\u001b[0m \n",
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=86197)\u001b[0m \n",
      "Stage 2: : 159it [00:00, 183.98it/s]\u001b[A\u001b[A pid=86197)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m Doing some training on epoch: 20 for batches: 20 and loss over batch: 0.025\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m Doing some training on epoch: 20 for batches: 20 and loss over batch: 0.026\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m == Pipeline Window 198 ==\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m Stage 1 read->randomize_block_order: 1/1 blocks executed in 0s\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m * Remote wall time: 134.46us min, 134.46us max, 134.46us mean, 134.46us total\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m * Remote cpu time: 135.0us min, 135.0us max, 135.0us mean, 135.0us total\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m * Peak heap memory usage (MiB): 154894336000.0 min, 154894336000.0 max, 154894336000 mean\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m * Output num rows: 50 min, 50 max, 50 mean, 50 total\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m * Output size bytes: 600 min, 600 max, 600 mean, 600 total\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m * Tasks per node: 1 min, 1 max, 1 mean; 1 nodes used\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m \n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m Stage 2 randomize_block_order: 1/1 blocks executed in 0s\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m * Remote wall time: 134.46us min, 134.46us max, 134.46us mean, 134.46us total\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m * Remote cpu time: 135.0us min, 135.0us max, 135.0us mean, 135.0us total\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m * Peak heap memory usage (MiB): 154894336000.0 min, 154894336000.0 max, 154894336000 mean\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m * Output num rows: 50 min, 50 max, 50 mean, 50 total\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m * Output size bytes: 600 min, 600 max, 600 mean, 600 total\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m * Tasks per node: 1 min, 1 max, 1 mean; 1 nodes used\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m \n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m == Pipeline Window 199 ==\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m Stage 1 read->randomize_block_order: 1/1 blocks executed in 0s\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m * Remote wall time: 126.04us min, 126.04us max, 126.04us mean, 126.04us total\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m * Remote cpu time: 126.0us min, 126.0us max, 126.0us mean, 126.0us total\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m * Peak heap memory usage (MiB): 154894336000.0 min, 154894336000.0 max, 154894336000 mean\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m * Output num rows: 50 min, 50 max, 50 mean, 50 total\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m * Output size bytes: 600 min, 600 max, 600 mean, 600 total\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m * Tasks per node: 1 min, 1 max, 1 mean; 1 nodes used\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m \n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m Stage 2 randomize_block_order: 1/1 blocks executed in 0s\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m * Remote wall time: 126.04us min, 126.04us max, 126.04us mean, 126.04us total\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m * Remote cpu time: 126.0us min, 126.0us max, 126.0us mean, 126.0us total\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m * Peak heap memory usage (MiB): 154894336000.0 min, 154894336000.0 max, 154894336000 mean\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m * Output num rows: 50 min, 50 max, 50 mean, 50 total\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m * Output size bytes: 600 min, 600 max, 600 mean, 600 total\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m * Tasks per node: 1 min, 1 max, 1 mean; 1 nodes used\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m \n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m == Pipeline Window 200 ==\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m Stage 1 read->randomize_block_order: 1/1 blocks executed in 0s\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m * Remote wall time: 121.21us min, 121.21us max, 121.21us mean, 121.21us total\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m * Remote cpu time: 121.0us min, 121.0us max, 121.0us mean, 121.0us total\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m * Peak heap memory usage (MiB): 154894336000.0 min, 154894336000.0 max, 154894336000 mean\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m * Output num rows: 50 min, 50 max, 50 mean, 50 total\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m * Output size bytes: 600 min, 600 max, 600 mean, 600 total\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m * Tasks per node: 1 min, 1 max, 1 mean; 1 nodes used\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m \n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m Stage 2 randomize_block_order: 1/1 blocks executed in 0s\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m * Remote wall time: 121.21us min, 121.21us max, 121.21us mean, 121.21us total\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m * Remote cpu time: 121.0us min, 121.0us max, 121.0us mean, 121.0us total\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m * Peak heap memory usage (MiB): 154894336000.0 min, 154894336000.0 max, 154894336000 mean\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m * Output num rows: 50 min, 50 max, 50 mean, 50 total\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m * Output size bytes: 600 min, 600 max, 600 mean, 600 total\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m * Tasks per node: 1 min, 1 max, 1 mean; 1 nodes used\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m \n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m ##### Overall Pipeline Time Breakdown #####\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m * Time stalled waiting for next dataset: 2.57ms min, 38.33ms max, 3.55ms mean, 710.94ms total\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=86194)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=86197)\u001b[0m \n",
      "Stage 0: : 166it [00:01, 185.07it/s]\u001b[Ator pid=86197)\u001b[0m \n",
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=86197)\u001b[0m \n",
      "Stage 2: : 180it [00:01, 190.00it/s]\u001b[A\u001b[A pid=86197)\u001b[0m \n",
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=86197)\u001b[0m \n",
      "Stage 0: : 186it [00:01, 188.54it/s]\u001b[Ator pid=86197)\u001b[0m \n",
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=86197)\u001b[0m \n",
      "Stage 2: : 200it [00:01, 192.24it/s]\u001b[A\u001b[A pid=86197)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for TorchTrainer_518ce_00000:\n",
      "  _time_this_iter_s: 0.1010432243347168\n",
      "  _timestamp: 1658009526\n",
      "  _training_iteration: 10\n",
      "  date: 2022-07-16_15-12-06\n",
      "  done: true\n",
      "  epoch: 20\n",
      "  experiment_id: 858e3fea072f4687a81dde9582592f9f\n",
      "  experiment_tag: '0'\n",
      "  hostname: Juless-MacBook-Pro-16\n",
      "  iterations_since_restore: 10\n",
      "  loss: 0.0255332714713642\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 86187\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 2.875962972640991\n",
      "  time_this_iter_s: 0.09958791732788086\n",
      "  time_total_s: 2.875962972640991\n",
      "  timestamp: 1658009526\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 10\n",
      "  trial_id: 518ce_00000\n",
      "  warmup_time: 0.0030679702758789062\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=86197)\u001b[0m /opt/miniconda3/envs/ray-build/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n",
      "\u001b[2m\u001b[36m(PipelineSplitExecutorCoordinator pid=86197)\u001b[0m   warnings.warn('resource_tracker: There appear to be %d '\n",
      "2022-07-16 15:12:07,056\tINFO tune.py:737 -- Total run time: 4.87 seconds (4.75 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "result = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e205d5a-6030-45f9-bf5a-4473c2343764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result(metrics={'loss': 0.022335927990326774, 'epoch': 20, '_timestamp': 1657944200, '_time_this_iter_s': 0.10506796836853027, '_training_iteration': 10, 'time_this_iter_s': 0.10604286193847656, 'should_checkpoint': True, 'done': True, 'timesteps_total': None, 'episodes_total': None, 'training_iteration': 10, 'trial_id': '38a86_00000', 'experiment_id': 'be17d5ff543b4e6b8e9df0efbb62c498', 'date': '2022-07-15_21-03-20', 'timestamp': 1657944200, 'time_total_s': 2.79736590385437, 'pid': 64653, 'hostname': 'Juless-MacBook-Pro-16', 'node_ip': '127.0.0.1', 'config': {}, 'time_since_restore': 2.79736590385437, 'timesteps_since_restore': 0, 'iterations_since_restore': 10, 'warmup_time': 0.002788066864013672, 'experiment_tag': '0'}, checkpoint=<ray.air.checkpoint.Checkpoint object at 0x130b2a460>, error=None, log_dir=PosixPath('/Users/jules/ray_results/TorchTrainer_2022-07-15_21-03-16/TorchTrainer_38a86_00000_0_2022-07-15_21-03-17'), metrics_dataframe=       loss  epoch  _timestamp  _time_this_iter_s  _training_iteration  \\\n",
      "0  0.026349     20  1657944199           0.800069                    1   \n",
      "1  0.024085     20  1657944200           0.110991                    2   \n",
      "2  0.016061     20  1657944200           0.106183                    3   \n",
      "3  0.021741     20  1657944200           0.108497                    4   \n",
      "4  0.031353     20  1657944200           0.104637                    5   \n",
      "5  0.026931     20  1657944200           0.103896                    6   \n",
      "6  0.025194     20  1657944200           0.103397                    7   \n",
      "7  0.023883     20  1657944200           0.104332                    8   \n",
      "8  0.022593     20  1657944200           0.104707                    9   \n",
      "9  0.022336     20  1657944200           0.105068                   10   \n",
      "\n",
      "   time_this_iter_s  should_checkpoint   done  timesteps_total  \\\n",
      "0          1.847592               True  False              NaN   \n",
      "1          0.108938               True  False              NaN   \n",
      "2          0.106517               True  False              NaN   \n",
      "3          0.107322               True  False              NaN   \n",
      "4          0.103504               True  False              NaN   \n",
      "5          0.103036               True  False              NaN   \n",
      "6          0.104543               True  False              NaN   \n",
      "7          0.103513               True  False              NaN   \n",
      "8          0.106358               True  False              NaN   \n",
      "9          0.106043               True  False              NaN   \n",
      "\n",
      "   episodes_total  ...                 date   timestamp time_total_s    pid  \\\n",
      "0             NaN  ...  2022-07-15_21-03-20  1657944200     1.847592  64653   \n",
      "1             NaN  ...  2022-07-15_21-03-20  1657944200     1.956530  64653   \n",
      "2             NaN  ...  2022-07-15_21-03-20  1657944200     2.063047  64653   \n",
      "3             NaN  ...  2022-07-15_21-03-20  1657944200     2.170369  64653   \n",
      "4             NaN  ...  2022-07-15_21-03-20  1657944200     2.273873  64653   \n",
      "5             NaN  ...  2022-07-15_21-03-20  1657944200     2.376909  64653   \n",
      "6             NaN  ...  2022-07-15_21-03-20  1657944200     2.481452  64653   \n",
      "7             NaN  ...  2022-07-15_21-03-20  1657944200     2.584965  64653   \n",
      "8             NaN  ...  2022-07-15_21-03-20  1657944200     2.691323  64653   \n",
      "9             NaN  ...  2022-07-15_21-03-20  1657944200     2.797366  64653   \n",
      "\n",
      "                hostname    node_ip  time_since_restore  \\\n",
      "0  Juless-MacBook-Pro-16  127.0.0.1            1.847592   \n",
      "1  Juless-MacBook-Pro-16  127.0.0.1            1.956530   \n",
      "2  Juless-MacBook-Pro-16  127.0.0.1            2.063047   \n",
      "3  Juless-MacBook-Pro-16  127.0.0.1            2.170369   \n",
      "4  Juless-MacBook-Pro-16  127.0.0.1            2.273873   \n",
      "5  Juless-MacBook-Pro-16  127.0.0.1            2.376909   \n",
      "6  Juless-MacBook-Pro-16  127.0.0.1            2.481452   \n",
      "7  Juless-MacBook-Pro-16  127.0.0.1            2.584965   \n",
      "8  Juless-MacBook-Pro-16  127.0.0.1            2.691323   \n",
      "9  Juless-MacBook-Pro-16  127.0.0.1            2.797366   \n",
      "\n",
      "  timesteps_since_restore iterations_since_restore  warmup_time  \n",
      "0                       0                        1     0.002788  \n",
      "1                       0                        2     0.002788  \n",
      "2                       0                        3     0.002788  \n",
      "3                       0                        4     0.002788  \n",
      "4                       0                        5     0.002788  \n",
      "5                       0                        6     0.002788  \n",
      "6                       0                        7     0.002788  \n",
      "7                       0                        8     0.002788  \n",
      "8                       0                        9     0.002788  \n",
      "9                       0                       10     0.002788  \n",
      "\n",
      "[10 rows x 23 columns], best_checkpoints=[(<ray.air.checkpoint.Checkpoint object at 0x130dbbaf0>, {'loss': 0.026348949776099986, 'epoch': 20, '_timestamp': 1657944199, '_time_this_iter_s': 0.8000690937042236, '_training_iteration': 1, 'time_this_iter_s': 1.8475918769836426, 'should_checkpoint': True, 'done': False, 'timesteps_total': None, 'episodes_total': None, 'training_iteration': 1, 'trial_id': '38a86_00000', 'experiment_id': 'be17d5ff543b4e6b8e9df0efbb62c498', 'date': '2022-07-15_21-03-20', 'timestamp': 1657944200, 'time_total_s': 1.8475918769836426, 'pid': 64653, 'hostname': 'Juless-MacBook-Pro-16', 'node_ip': '127.0.0.1', 'config': {}, 'time_since_restore': 1.8475918769836426, 'timesteps_since_restore': 0, 'iterations_since_restore': 1, 'warmup_time': 0.002788066864013672, 'experiment_tag': '0'}), (<ray.air.checkpoint.Checkpoint object at 0x130dbbe80>, {'loss': 0.024085382205486908, 'epoch': 20, '_timestamp': 1657944200, '_time_this_iter_s': 0.11099076271057129, '_training_iteration': 2, 'time_this_iter_s': 0.10893821716308594, 'should_checkpoint': True, 'done': False, 'timesteps_total': None, 'episodes_total': None, 'training_iteration': 2, 'trial_id': '38a86_00000', 'experiment_id': 'be17d5ff543b4e6b8e9df0efbb62c498', 'date': '2022-07-15_21-03-20', 'timestamp': 1657944200, 'time_total_s': 1.9565300941467285, 'pid': 64653, 'hostname': 'Juless-MacBook-Pro-16', 'node_ip': '127.0.0.1', 'config': {}, 'time_since_restore': 1.9565300941467285, 'timesteps_since_restore': 0, 'iterations_since_restore': 2, 'warmup_time': 0.002788066864013672, 'experiment_tag': '0'}), (<ray.air.checkpoint.Checkpoint object at 0x12ff07b50>, {'loss': 0.01606098994353204, 'epoch': 20, '_timestamp': 1657944200, '_time_this_iter_s': 0.10618329048156738, '_training_iteration': 3, 'time_this_iter_s': 0.10651707649230957, 'should_checkpoint': True, 'done': False, 'timesteps_total': None, 'episodes_total': None, 'training_iteration': 3, 'trial_id': '38a86_00000', 'experiment_id': 'be17d5ff543b4e6b8e9df0efbb62c498', 'date': '2022-07-15_21-03-20', 'timestamp': 1657944200, 'time_total_s': 2.063047170639038, 'pid': 64653, 'hostname': 'Juless-MacBook-Pro-16', 'node_ip': '127.0.0.1', 'config': {}, 'time_since_restore': 2.063047170639038, 'timesteps_since_restore': 0, 'iterations_since_restore': 3, 'warmup_time': 0.002788066864013672, 'experiment_tag': '0'}), (<ray.air.checkpoint.Checkpoint object at 0x12cc048e0>, {'loss': 0.021740646133656758, 'epoch': 20, '_timestamp': 1657944200, '_time_this_iter_s': 0.10849690437316895, '_training_iteration': 4, 'time_this_iter_s': 0.10732173919677734, 'should_checkpoint': True, 'done': False, 'timesteps_total': None, 'episodes_total': None, 'training_iteration': 4, 'trial_id': '38a86_00000', 'experiment_id': 'be17d5ff543b4e6b8e9df0efbb62c498', 'date': '2022-07-15_21-03-20', 'timestamp': 1657944200, 'time_total_s': 2.1703689098358154, 'pid': 64653, 'hostname': 'Juless-MacBook-Pro-16', 'node_ip': '127.0.0.1', 'config': {}, 'time_since_restore': 2.1703689098358154, 'timesteps_since_restore': 0, 'iterations_since_restore': 4, 'warmup_time': 0.002788066864013672, 'experiment_tag': '0'}), (<ray.air.checkpoint.Checkpoint object at 0x130dbba60>, {'loss': 0.031352627484661416, 'epoch': 20, '_timestamp': 1657944200, '_time_this_iter_s': 0.10463690757751465, '_training_iteration': 5, 'time_this_iter_s': 0.10350418090820312, 'should_checkpoint': True, 'done': False, 'timesteps_total': None, 'episodes_total': None, 'training_iteration': 5, 'trial_id': '38a86_00000', 'experiment_id': 'be17d5ff543b4e6b8e9df0efbb62c498', 'date': '2022-07-15_21-03-20', 'timestamp': 1657944200, 'time_total_s': 2.2738730907440186, 'pid': 64653, 'hostname': 'Juless-MacBook-Pro-16', 'node_ip': '127.0.0.1', 'config': {}, 'time_since_restore': 2.2738730907440186, 'timesteps_since_restore': 0, 'iterations_since_restore': 5, 'warmup_time': 0.002788066864013672, 'experiment_tag': '0'}), (<ray.air.checkpoint.Checkpoint object at 0x1308c0fd0>, {'loss': 0.02693105750242389, 'epoch': 20, '_timestamp': 1657944200, '_time_this_iter_s': 0.1038961410522461, '_training_iteration': 6, 'time_this_iter_s': 0.10303592681884766, 'should_checkpoint': True, 'done': False, 'timesteps_total': None, 'episodes_total': None, 'training_iteration': 6, 'trial_id': '38a86_00000', 'experiment_id': 'be17d5ff543b4e6b8e9df0efbb62c498', 'date': '2022-07-15_21-03-20', 'timestamp': 1657944200, 'time_total_s': 2.376909017562866, 'pid': 64653, 'hostname': 'Juless-MacBook-Pro-16', 'node_ip': '127.0.0.1', 'config': {}, 'time_since_restore': 2.376909017562866, 'timesteps_since_restore': 0, 'iterations_since_restore': 6, 'warmup_time': 0.002788066864013672, 'experiment_tag': '0'}), (<ray.air.checkpoint.Checkpoint object at 0x1308c0e20>, {'loss': 0.025194439661929066, 'epoch': 20, '_timestamp': 1657944200, '_time_this_iter_s': 0.10339689254760742, '_training_iteration': 7, 'time_this_iter_s': 0.10454297065734863, 'should_checkpoint': True, 'done': False, 'timesteps_total': None, 'episodes_total': None, 'training_iteration': 7, 'trial_id': '38a86_00000', 'experiment_id': 'be17d5ff543b4e6b8e9df0efbb62c498', 'date': '2022-07-15_21-03-20', 'timestamp': 1657944200, 'time_total_s': 2.481451988220215, 'pid': 64653, 'hostname': 'Juless-MacBook-Pro-16', 'node_ip': '127.0.0.1', 'config': {}, 'time_since_restore': 2.481451988220215, 'timesteps_since_restore': 0, 'iterations_since_restore': 7, 'warmup_time': 0.002788066864013672, 'experiment_tag': '0'}), (<ray.air.checkpoint.Checkpoint object at 0x1308c0250>, {'loss': 0.023882888637008003, 'epoch': 20, '_timestamp': 1657944200, '_time_this_iter_s': 0.10433197021484375, '_training_iteration': 8, 'time_this_iter_s': 0.10351300239562988, 'should_checkpoint': True, 'done': False, 'timesteps_total': None, 'episodes_total': None, 'training_iteration': 8, 'trial_id': '38a86_00000', 'experiment_id': 'be17d5ff543b4e6b8e9df0efbb62c498', 'date': '2022-07-15_21-03-20', 'timestamp': 1657944200, 'time_total_s': 2.5849649906158447, 'pid': 64653, 'hostname': 'Juless-MacBook-Pro-16', 'node_ip': '127.0.0.1', 'config': {}, 'time_since_restore': 2.5849649906158447, 'timesteps_since_restore': 0, 'iterations_since_restore': 8, 'warmup_time': 0.002788066864013672, 'experiment_tag': '0'}), (<ray.air.checkpoint.Checkpoint object at 0x1308c0280>, {'loss': 0.02259325500146996, 'epoch': 20, '_timestamp': 1657944200, '_time_this_iter_s': 0.10470700263977051, '_training_iteration': 9, 'time_this_iter_s': 0.10635805130004883, 'should_checkpoint': True, 'done': False, 'timesteps_total': None, 'episodes_total': None, 'training_iteration': 9, 'trial_id': '38a86_00000', 'experiment_id': 'be17d5ff543b4e6b8e9df0efbb62c498', 'date': '2022-07-15_21-03-20', 'timestamp': 1657944200, 'time_total_s': 2.6913230419158936, 'pid': 64653, 'hostname': 'Juless-MacBook-Pro-16', 'node_ip': '127.0.0.1', 'config': {}, 'time_since_restore': 2.6913230419158936, 'timesteps_since_restore': 0, 'iterations_since_restore': 9, 'warmup_time': 0.002788066864013672, 'experiment_tag': '0'}), (<ray.air.checkpoint.Checkpoint object at 0x1308d10a0>, {'loss': 0.022335927990326774, 'epoch': 20, '_timestamp': 1657944200, '_time_this_iter_s': 0.10506796836853027, '_training_iteration': 10, 'time_this_iter_s': 0.10604286193847656, 'should_checkpoint': True, 'done': True, 'timesteps_total': None, 'episodes_total': None, 'training_iteration': 10, 'trial_id': '38a86_00000', 'experiment_id': 'be17d5ff543b4e6b8e9df0efbb62c498', 'date': '2022-07-15_21-03-20', 'timestamp': 1657944200, 'time_total_s': 2.79736590385437, 'pid': 64653, 'hostname': 'Juless-MacBook-Pro-16', 'node_ip': '127.0.0.1', 'config': {}, 'time_since_restore': 2.79736590385437, 'timesteps_since_restore': 0, 'iterations_since_restore': 10, 'warmup_time': 0.002788066864013672, 'experiment_tag': '0'})])\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a8b6ff5-1991-45de-ab59-c38d68226fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7090d519-7405-485e-a2a4-f295977b7835",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
