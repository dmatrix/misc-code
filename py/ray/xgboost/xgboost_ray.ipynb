{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4290d6a6-0dec-4172-8054-581fc8d2c9a4",
   "metadata": {},
   "source": [
    "## XGBoost on a single node \n",
    "\n",
    "Code example from [Anyscale blog]()\n",
    "\n",
    "Let's first start by creating a simple single node non-distributed setup with core XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c248ed4-0608-4b59-aaa1-81b3011b6f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13607fe-5a2a-4db1-bb6b-8d2cfa923615",
   "metadata": {},
   "source": [
    "### Load the scikit-learn data and convert to XGBoot DMatrix data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccbcf06c-23a0-4040-9335-7a6f281958a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = load_breast_cancer(return_X_y=True)\n",
    "train_set = xgb.DMatrix(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81bc8f9b-b310-4c60-8243-5d83d9224934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost train time: 0.03 secs\n"
     ]
    }
   ],
   "source": [
    "# Train the model with required arguments to XGBoost trainger\n",
    "\n",
    "evals_result = {}\n",
    "start = time.time()\n",
    "bst = xgb.train({\"objective\": \"binary:logistic\",\n",
    "            \"eval_metric\": [\"logloss\", \"error\"] },\n",
    "            train_set,\n",
    "            evals_result=evals_result,\n",
    "            evals=[(train_set, \"train\")],\n",
    "            verbose_eval=False)\n",
    "\n",
    "print(\"XGBoost train time: {:.2f} secs\".format(time.time() - start))\n",
    "\n",
    "# Save the model\n",
    "bst.save_model(\"model.xgb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbc7ac1-e219-47fb-9e94-f116e0674784",
   "metadata": {},
   "source": [
    "### Do predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9fb5747-477a-4e9c-81a4-847ad2bde98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost import DMatrix, predict\n",
    "# from sklearn.datasets import load_breast_cancer\n",
    "# import xgboost as xgb\n",
    "\n",
    "# data, labels = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "# dpred = DMatrix(data, labels)\n",
    "\n",
    "# bst = xgb.Booster(model_file=\"model.xgb\")\n",
    "# predictions = predict(bst, dpred)\n",
    "\n",
    "# print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8fb0ec-5e4e-4576-9ca6-93e98c64fba7",
   "metadata": {},
   "source": [
    "### XGBoost-ray on multiple cores\n",
    "\n",
    "Import the Ray integrated xgboost parameters and trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf64c6ec-d12b-4266-be60-6551401538a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-21 13:05:11,901\tINFO main.py:892 -- [RayXGBoost] Created 2 new actors (2 total actors). Waiting until actors are ready for training.\n",
      "2021-08-21 13:05:12,722\tINFO main.py:937 -- [RayXGBoost] Starting XGBoost training.\n",
      "\u001b[2m\u001b[36m(pid=36640)\u001b[0m [13:05:12] task [xgboost.ray]:140695871277280 got new rank 0\n",
      "\u001b[2m\u001b[36m(pid=36635)\u001b[0m [13:05:12] task [xgboost.ray]:140203359316192 got new rank 1\n",
      "2021-08-21 13:05:13,604\tINFO main.py:1408 -- [RayXGBoost] Finished XGBoost training on training data with total N=569 in 1.76 seconds (0.88 pure XGBoost training time).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost train time: 1.77 secs\n"
     ]
    }
   ],
   "source": [
    "from xgboost_ray import RayDMatrix, RayParams, train\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "train_x, train_y = load_breast_cancer(return_X_y=True)\n",
    "train_set = RayDMatrix(train_x, train_y)\n",
    "\n",
    "evals_result = {}\n",
    "start = time.time()\n",
    "bst = train(\n",
    "   {\n",
    "       \"objective\": \"binary:logistic\",\n",
    "       \"eval_metric\": [\"logloss\", \"error\"],\n",
    "   },\n",
    "   train_set,\n",
    "   evals_result=evals_result,\n",
    "   evals=[(train_set, \"train\")],\n",
    "   verbose_eval=False,\n",
    "   ray_params=RayParams(num_actors=2, cpus_per_actor=1))\n",
    "\n",
    "print(\"XGBoost train time: {:.2f} secs\".format(time.time() - start))\n",
    "\n",
    "bst.save_model(\"model_ray.xgb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac44a4f8-8151-468c-ba0b-09d1b75ca449",
   "metadata": {},
   "source": [
    "### Scikit-learn API\n",
    "\n",
    "XGBoost-Ray can also act as a drop-in replacement for sklearn-style models, such as XGBRegressor or XGBClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bca39aff-9a74-462f-8182-42e805a9087d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021/08/21 17:15:37 INFO mlflow.tracking.fluent: Autologging successfully enabled for xgboost.\n",
      "2021/08/21 17:15:41 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "/Users/jules/miniconda3/lib/python3.9/site-packages/xgboost_ray/sklearn.py:749: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "2021-08-21 17:15:42,918\tINFO main.py:892 -- [RayXGBoost] Created 4 new actors (4 total actors). Waiting until actors are ready for training.\n",
      "2021-08-21 17:15:44,242\tINFO main.py:937 -- [RayXGBoost] Starting XGBoost training.\n",
      "\u001b[2m\u001b[36m(pid=37446)\u001b[0m [17:15:44] task [xgboost.ray]:140441235322864 got new rank 0\n",
      "\u001b[2m\u001b[36m(pid=37453)\u001b[0m [17:15:44] task [xgboost.ray]:140395525882496 got new rank 1\n",
      "\u001b[2m\u001b[36m(pid=37449)\u001b[0m [17:15:44] task [xgboost.ray]:140316194740160 got new rank 3\n",
      "\u001b[2m\u001b[36m(pid=37447)\u001b[0m [17:15:44] task [xgboost.ray]:140195935647776 got new rank 2\n",
      "\u001b[2m\u001b[36m(pid=37446)\u001b[0m [17:15:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[2m\u001b[36m(pid=37453)\u001b[0m [17:15:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[2m\u001b[36m(pid=37449)\u001b[0m [17:15:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[2m\u001b[36m(pid=37447)\u001b[0m [17:15:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-08-21 17:15:45,551\tINFO main.py:1408 -- [RayXGBoost] Finished XGBoost training on training data with total N=569 in 3.91 seconds (1.30 pure XGBoost training time).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost train time: 7.86 secs\n"
     ]
    }
   ],
   "source": [
    "from xgboost_ray import RayXGBClassifier, RayParams\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import mlflow\n",
    "\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "clf = RayXGBClassifier(\n",
    "    n_jobs=4,  # Number of distributed actors\n",
    ")\n",
    "start = time.time()\n",
    "mlflow.autolog()\n",
    "clf.fit(X, y)\n",
    "print(\"XGBoost train time: {:.2f} secs\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff12093c-ade3-4bd1-bdbd-334b2308fcb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
