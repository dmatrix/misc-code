{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b63eb91c-8a7d-45cd-b266-76a6add9e5fe",
   "metadata": {},
   "source": [
    "## Ray integration with Ray, Serve, LangChain, and OpenAI \n",
    "\n",
    "<img src=\"ray_langchain.png\" width=\"50%\" height=\"25%\">\n",
    "\n",
    "The process involves two stages.\n",
    "\n",
    "1. Building the vector embeddings indexes from the pdf document and storing them into a Chroma database. \n",
    "For long documents, exceeding hundreds of pages, they can split and parallelized with Ray tasks. \n",
    "2. Once the Chroma vector embeddings database is built, we can read the embeddings from the disk, we load the embeddings\n",
    "from disk.\n",
    "\n",
    "<img src=\"create_index_flow.png\" width=\"70%\" height=\"35%\">\n",
    "\n",
    "Our pdf document is an AI report, which is 351 pages, small enough for one remote Ray task\n",
    "\n",
    "<img src=\"ai_report.png\" width=\"20%\" height=\"10%\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72230835-a8c3-4951-a4f5-4db004d85e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader \n",
    "from langchain.embeddings import OpenAIEmbeddings \n",
    "from langchain.vectorstores import Chroma \n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "from ray import serve\n",
    "from starlette.requests import Request\n",
    "\n",
    "# simple example inspired from \n",
    "# https://medium.com/geekculture/automating-pdf-interaction-with-langchain-and-chatgpt-e723337f26a6\n",
    "# and https://github.com/sophiamyang/tutorials-LangChain/tree/main\n",
    "# Default model used is OpenAI: default-gpt-3.5-turbo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ae7e04-b22b-4b04-b7ab-d4e6ba98e12b",
   "metadata": {},
   "source": [
    "#### Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a5ee992-bc9e-4df8-8ac2-5b33896e2397",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPEN_AI_KEY = \"your_key\"\n",
    "VECTOR_OPEN_AI_DB = \"vector_oai_db\"\n",
    "vector_db = Path(Path.cwd(), VECTOR_OPEN_AI_DB).as_posix()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a5b5e3-110a-487c-aeac-5e4b631fdb56",
   "metadata": {},
   "source": [
    "### Create our Serve deployment class\n",
    "\n",
    "  * Load the respective embeddings from the [Chroma Vector Store](https://python.langchain.com/en/latest/ecosystem/chroma.html)\n",
    "  * Initiates a LangChain high-level abstraction, which provides interface to OpenAI's `default-gpt-3.5-turbo` large language model\n",
    "  * The callable class uses the LangChain interface to send request to the model for response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fee6ba4b-846e-48e8-a7b6-fa01949150d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@serve.deployment(route_prefix=\"/\",\n",
    "                  autoscaling_config={\n",
    "                        \"min_replicas\": 2,\n",
    "                        \"initial_replicas\": 2,\n",
    "                        \"max_replicas\": 4,\n",
    "    })\n",
    "class AnswerOpenAIPDFQuestions():\n",
    "    def __init__(self, vector_db_path: str, open_ai_key: str):\n",
    "\n",
    "        \n",
    "        os.environ[\"OPENAI_API_KEY\"] = open_ai_key\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "        self._vectordb = Chroma(persist_directory=vector_db_path, embedding_function=embeddings)\n",
    "        self._pdf_qa_chain = ConversationalRetrievalChain.from_llm(ChatOpenAI(temperature=0.9), \n",
    "                                                             self._vectordb.as_retriever())\n",
    "        self._chat_history=[]\n",
    "\n",
    "    async def __call__(self, http_request: Request) -> str:\n",
    "        json_request: str = await http_request.json()\n",
    "        prompts = []\n",
    "        for prompt in json_request:\n",
    "            text = prompt[\"text\"]\n",
    "            if isinstance(text, list):\n",
    "                prompts.extend(text)\n",
    "            else:\n",
    "                prompts.append(text)\n",
    "        result = self._pdf_qa_chain({\"question\": prompts[0], \"chat_history\": self._chat_history})\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddfb5ef-b250-4c77-87c3-12c37777bb64",
   "metadata": {},
   "source": [
    "### Create Serve deployment. \n",
    "This is deployment has couple of replicas that can serve prompts or questions and return \n",
    "responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0046606e-fbfd-42ad-8c08-f074b64da2de",
   "metadata": {},
   "source": [
    "### Send questions to the LLM model served by Serve\n",
    "\n",
    "<img src=\"ray_serve_request_response.png\" width=\"50%\" height=\"25%\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "504ab269-4caa-4e4b-acf9-07d771f9be81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send the request to the deployment\n",
    "prompts = [ \"What is the total number of publications?\",\n",
    "            \"What is the percentage increase in the number of AI-related job postings?\",\n",
    "            \"Why Chinese citizens are more optimistic about AI than Americans?\",\n",
    "            # \"What are the top takeaways from this report?\",\n",
    "            # \"List benchmarks are released to evaulate AI workloads?\",\n",
    "            # \"Describe and summarize the techincal ethical issues raised in the report?\",\n",
    "            # \"How many bills containing “artificial intelligence” were passed into law?\",\n",
    "            # \"What is the percentage increase in the number of AI-related job postings?\"      \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32d896cd-fc23-427d-8da8-9f2b76208606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the total number of publications?\n",
      "Answer: From 2010 to 2021, the total number of AI publications more than doubled, growing from 200,000 in 2010 to almost 500,000 in 2021. However, it is important to note that this only includes English-language and Chinese-language AI publications globally.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=50775)\u001b[0m INFO 2023-04-21 11:10:49,270 http_proxy 127.0.0.1 http_proxy.py:373 - POST / 200 5465.9ms\n",
      "\u001b[2m\u001b[36m(ServeReplica:AnswerOpenAIPDFQuestions pid=50778)\u001b[0m INFO 2023-04-21 11:10:49,265 AnswerOpenAIPDFQuestions AnswerOpenAIPDFQuestions#AfPppG replica.py:518 - HANDLE __call__ OK 5455.8ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the percentage increase in the number of AI-related job postings?\n",
      "Answer: The data provides information on an increase in AI-related job postings, but it does not provide a single percentage increase across all job postings. It shows percentage increases and rankings by country, geographic area, sector, and state for different time periods.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=50775)\u001b[0m INFO 2023-04-21 11:10:53,386 http_proxy 127.0.0.1 http_proxy.py:373 - POST / 200 4103.2ms\n",
      "\u001b[2m\u001b[36m(ServeReplica:AnswerOpenAIPDFQuestions pid=50777)\u001b[0m INFO 2023-04-21 11:10:53,381 AnswerOpenAIPDFQuestions AnswerOpenAIPDFQuestions#hsvqBJ replica.py:518 - HANDLE __call__ OK 4091.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Why Chinese citizens are more optimistic about AI than Americans?\n",
      "Answer: According to a 2022 IPSOS survey, 78% of Chinese respondents agreed with the statement that products and services using AI have more benefits than drawbacks, whereas only 35% of sampled Americans agreed with this statement. The report does not provide a clear explanation for why Chinese citizens are more optimistic about AI than Americans. However, it does suggest that opinions about AI vary across countries, and sentiment relating to AI products and services seems to be strongly correlated within specific countries.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_inputs = [{\"text\": prompt} for prompt in prompts]\n",
    "for sample_input in sample_inputs:\n",
    "    output = requests.post(\"http://localhost:8000/\", json=[sample_input]).json()\n",
    "    print(f\"Question: {output['question']}\\nAnswer: {output['answer']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d9f6b05-9823-4d86-b94e-fe23a418bf2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=50775)\u001b[0m INFO 2023-04-21 11:11:00,307 http_proxy 127.0.0.1 http_proxy.py:373 - POST / 200 6912.8ms\n",
      "\u001b[2m\u001b[36m(ServeReplica:AnswerOpenAIPDFQuestions pid=50778)\u001b[0m INFO 2023-04-21 11:11:00,303 AnswerOpenAIPDFQuestions AnswerOpenAIPDFQuestions#AfPppG replica.py:518 - HANDLE __call__ OK 6903.1ms\n",
      "\u001b[2m\u001b[36m(ServeController pid=50769)\u001b[0m INFO 2023-04-21 11:11:01,849 controller 50769 deployment_state.py:1359 - Removing 2 replicas from deployment 'AnswerOpenAIPDFQuestions'.\n"
     ]
    }
   ],
   "source": [
    "serve.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
