{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FahrenheitTemperatures(Dataset):\n",
    "    def __init__(self, start=-212, stop=10512, step=2):\n",
    "        super(FahrenheitTemperatures, self).__init__()\n",
    "        \n",
    "        # Intialize local variables and covert them into tensors\n",
    "        self.X = torch.from_numpy(np.arange(start, stop, step, dtype=float))\n",
    "        self.y = torch.from_numpy(np.array([self._f2c(f) for f in self.X], dtype=float))\n",
    "        self.X_p = torch.from_numpy(np.arange(212, 170, -5, dtype=float))\n",
    "        self.n_samples = self.X.shape[0]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # support indexing such that dataset[i] can be used to get i-th sample\n",
    "        # implement this python function for indexing\n",
    "        return self.X[index], self.y[index]\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        # we can call len(dataset) to return the size, so this can be used\n",
    "        # as an iterator\n",
    "        return self.n_samples\n",
    "    \n",
    "    def _f2c(sel,f) -> float:\n",
    "        return (f - 32) * 5.0/9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fahrenheit: -212.00\n",
      "Celcius   : -135.56\n"
     ]
    }
   ],
   "source": [
    "# Let's now access our dataset\n",
    "dataset =FahrenheitTemperatures()\n",
    "first_dataset = dataset[0]\n",
    "features, labels = first_dataset\n",
    "print('Fahrenheit: {:.2f}'.format(features))\n",
    "print('Celcius   : {:.2f}'.format(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 5362\n",
      "Number of iterations: 1341\n"
     ]
    }
   ],
   "source": [
    "# Now we can use the dataloader and iterator in a training loop\n",
    "\n",
    "num_epochs = 2\n",
    "batch_size = 4\n",
    "total_samples = len(dataset)\n",
    "n_iterations = math.ceil(total_samples/batch_size)\n",
    "\n",
    "print('Number of samples: {}'.format(total_samples))\n",
    "print('Number of iterations: {}'.format(n_iterations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fahrenheit: -212.0\n",
      "Celcius   : tensor([4913.3333, 3398.8889, 5362.2222, 5694.4444], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Let's try Dataloader class and make this into an iterator and access the data as above\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "dataiter = iter(dataloader)\n",
    "data = dataiter.next()\n",
    "feartures, labels = data\n",
    "\n",
    "# since we specified our batch size to be 4, we'll see four features and labels\n",
    "print('Fahrenheit: {}'.format(features))\n",
    "print('Celcius   : {}'.format(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2, Step 400/1341| Inputs torch.Size([4]) | Labels torch.Size([4]), Tensors tensor([1668., 5680.,  520., 2916.], dtype=torch.float64)\n",
      "Epoch: 1/2, Step 800/1341| Inputs torch.Size([4]) | Labels torch.Size([4]), Tensors tensor([ 3068., 10474., 10138.,  9616.], dtype=torch.float64)\n",
      "Epoch: 1/2, Step 1200/1341| Inputs torch.Size([4]) | Labels torch.Size([4]), Tensors tensor([8264., 9876., 6564., 3120.], dtype=torch.float64)\n",
      "Epoch: 2/2, Step 400/1341| Inputs torch.Size([4]) | Labels torch.Size([4]), Tensors tensor([6184.,  650., 1674.,  316.], dtype=torch.float64)\n",
      "Epoch: 2/2, Step 800/1341| Inputs torch.Size([4]) | Labels torch.Size([4]), Tensors tensor([7986., 2532., 5888., 7944.], dtype=torch.float64)\n",
      "Epoch: 2/2, Step 1200/1341| Inputs torch.Size([4]) | Labels torch.Size([4]), Tensors tensor([2570., 4188., 8420., 6810.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# let's do a dummy training loop\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # iterate over our dataloader in batches\n",
    "    # Because we have implemented our Dataset class with __getitem__ and __len__, we\n",
    "    # can iterate over it\n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "        # forward and backward pass, update gradients, and zero them out\n",
    "        # Run your training process\n",
    "        if (i+1) % 400 == 0:\n",
    "            print(f'Epoch: {epoch+1}/{num_epochs}, Step {i+1}/{n_iterations}| Inputs {inputs.shape} | Labels {labels.shape}, Tensors {inputs}')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(np.arange(1., 100.))\n",
    "y = torch.from_numpy(np.array([(x*2) for x in X]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.,\n",
       "        15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26., 27., 28.,\n",
       "        29., 30., 31., 32., 33., 34., 35., 36., 37., 38., 39., 40., 41., 42.,\n",
       "        43., 44., 45., 46., 47., 48., 49., 50., 51., 52., 53., 54., 55., 56.,\n",
       "        57., 58., 59., 60., 61., 62., 63., 64., 65., 66., 67., 68., 69., 70.,\n",
       "        71., 72., 73., 74., 75., 76., 77., 78., 79., 80., 81., 82., 83., 84.,\n",
       "        85., 86., 87., 88., 89., 90., 91., 92., 93., 94., 95., 96., 97., 98.,\n",
       "        99.], dtype=torch.float64)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,  24.,\n",
       "         26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,  48.,\n",
       "         50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,  72.,\n",
       "         74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,  96.,\n",
       "         98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118., 120.,\n",
       "        122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142., 144.,\n",
       "        146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166., 168.,\n",
       "        170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190., 192.,\n",
       "        194., 196., 198.], dtype=torch.float64)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.],\n",
       "         [2.],\n",
       "         [3.]]),\n",
       " torch.Size([3, 1]))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = torch.Tensor([[1.0], [2.0], [3.0]])\n",
    "x_data, x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.],\n",
       "         [ 2.],\n",
       "         [ 3.],\n",
       "         [ 4.],\n",
       "         [ 5.],\n",
       "         [ 6.],\n",
       "         [ 7.],\n",
       "         [ 8.],\n",
       "         [ 9.],\n",
       "         [10.],\n",
       "         [11.],\n",
       "         [12.],\n",
       "         [13.],\n",
       "         [14.],\n",
       "         [15.],\n",
       "         [16.],\n",
       "         [17.],\n",
       "         [18.],\n",
       "         [19.],\n",
       "         [20.],\n",
       "         [21.],\n",
       "         [22.],\n",
       "         [23.],\n",
       "         [24.],\n",
       "         [25.],\n",
       "         [26.],\n",
       "         [27.],\n",
       "         [28.],\n",
       "         [29.],\n",
       "         [30.],\n",
       "         [31.],\n",
       "         [32.],\n",
       "         [33.],\n",
       "         [34.],\n",
       "         [35.],\n",
       "         [36.],\n",
       "         [37.],\n",
       "         [38.],\n",
       "         [39.],\n",
       "         [40.],\n",
       "         [41.],\n",
       "         [42.],\n",
       "         [43.],\n",
       "         [44.],\n",
       "         [45.],\n",
       "         [46.],\n",
       "         [47.],\n",
       "         [48.],\n",
       "         [49.],\n",
       "         [50.],\n",
       "         [51.],\n",
       "         [52.],\n",
       "         [53.],\n",
       "         [54.],\n",
       "         [55.],\n",
       "         [56.],\n",
       "         [57.],\n",
       "         [58.],\n",
       "         [59.],\n",
       "         [60.],\n",
       "         [61.],\n",
       "         [62.],\n",
       "         [63.],\n",
       "         [64.],\n",
       "         [65.],\n",
       "         [66.],\n",
       "         [67.],\n",
       "         [68.],\n",
       "         [69.],\n",
       "         [70.],\n",
       "         [71.],\n",
       "         [72.],\n",
       "         [73.],\n",
       "         [74.],\n",
       "         [75.],\n",
       "         [76.],\n",
       "         [77.],\n",
       "         [78.],\n",
       "         [79.],\n",
       "         [80.],\n",
       "         [81.],\n",
       "         [82.],\n",
       "         [83.],\n",
       "         [84.],\n",
       "         [85.],\n",
       "         [86.],\n",
       "         [87.],\n",
       "         [88.],\n",
       "         [89.],\n",
       "         [90.],\n",
       "         [91.],\n",
       "         [92.],\n",
       "         [93.],\n",
       "         [94.],\n",
       "         [95.],\n",
       "         [96.],\n",
       "         [97.],\n",
       "         [98.],\n",
       "         [99.]], dtype=torch.float64),\n",
       " torch.Size([99, 1]))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = X.view(-1, 1)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(1, 5).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.arange(1, 10, dtype=np.float).view(-1, 1)\n",
    "y = torch.from_numpy(np.array([(x * 2) for x in X], dtype=np.float)).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [4.],\n",
       "        [5.],\n",
       "        [6.],\n",
       "        [7.],\n",
       "        [8.],\n",
       "        [9.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.],\n",
       "        [ 4.],\n",
       "        [ 6.],\n",
       "        [ 8.],\n",
       "        [10.],\n",
       "        [12.],\n",
       "        [14.],\n",
       "        [16.],\n",
       "        [18.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
