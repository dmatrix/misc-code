{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build our first neural network\n",
    "\n",
    "1. Define data, input, hidden, and output layers\n",
    "3. Multi-layer Neural Network\n",
    "4. Loss and Optimizer\n",
    "5. Training loop (batch optimzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random Tensors to hold inputs and outputs\n",
    "X = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet(nn.Module):\n",
    "    \"\"\"\n",
    "    In the constructor we instantiate two nn.Linear modules and assign them as\n",
    "    member variables.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_layers, output_size):\n",
    "        super(TwoLayerNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_layers)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_layers, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Tensor of input data and we must return\n",
    "        a Tensor of output data. We can use Modules defined in the constructor as\n",
    "        well as arbitrary (differentiable) operations on Tensors.\n",
    "        \"\"\"\n",
    "        y_pred = self.l1(x)\n",
    "        y_pred = self.relu(y_pred)\n",
    "        y_pred = self.l2(y_pred)\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct our model by instantiating the class defined above.\n",
    "model = TwoLayerNet(D_in, H, D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct our loss function and an Optimizer. The call to model.parameters()\n",
    "# in the SGD constructor will contain the learnable parameters of the two\n",
    "# nn.Linear modules which are members of the model.\n",
    "learning_rate = 1e-4\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our training loop\n",
    "for t in range(500):\n",
    "    \n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred = model(X)\n",
    "    \n",
    "    # Compute and print loss\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    print(t, loss.item())\n",
    "    \n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.set()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
