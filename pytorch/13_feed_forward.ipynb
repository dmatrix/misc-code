{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build our first neural network\n",
    "\n",
    "1. MNIST Dataset\n",
    "2. DataLoader and Transformations\n",
    "3. Multi-layer Neural Network\n",
    "4. Loss and Optimizer\n",
    "5. Training loop (batch optimzer)\n",
    "6. Model Evaluation\n",
    "7. GPU support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transform\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Device configuration to use if GPU available and hyperparaters configuration\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# tunable hyperparameters\n",
    "hidden_size = 100        # this parameter can be tuned to affect the training accuracy \n",
    "num_epochs = 500         # this parameter can be tuned to affect the training accuracy\n",
    "batch_size = 100         # this parameter can be tuned to affect the training accuracy\n",
    "learning_rate = 0.001    # this parameter can be tuned to affect the training accuracy\n",
    "\n",
    "# fixed parameters\n",
    "input_size = 784        # images are 28x28 pixels, convert that in flattened 1-d tensor\n",
    "num_classes = 10        # 10 different digits to classify: 0-9\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 & 2. MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "# Download the training and test datasets\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                          transform=transform.ToTensor(), download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                          transform=transform.ToTensor(), download=False)\n",
    "\n",
    "# Define the Dataloader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Get the first dataset as tensors and unpack it\n",
    "examples = iter(train_loader)\n",
    "features, labels = examples.next()\n",
    "\n",
    "# samples=100 in our batch; 1 is the channel (not RGB); 28 x 28 is our image sizez\n",
    "print(features.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine what our data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD6CAYAAAC4RRw1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAcW0lEQVR4nO3dfZAUxfkH8O/jeRIDJhy+kAOOFxOlJBKRECuEBH8qKPhSpIpQJSnktKjCCKa0BAOIEgwRKSviS0TNGQgYLCCokZfEwpNgEk2geAkiL3UcEIGTgyNqCsSgoP3745a2e7jdnZudnZme/X6qru7p7d2Zhmevb663p1uUUiAiIvecEXcDiIgoGHbgRESOYgdOROQoduBERI5iB05E5Ch24EREjiqoAxeRISJSJyK7RGRyWI2ieDGv6cXcposEnQcuImUAdgIYDKABwHoAI5VS28NrHkWNeU0v5jZ9zizgtVcA2KWU2gMAIrIYwDAAWd8MIsK7hhJCKSVZqphXt/1HKXV+lrpW5ZZ5TZQW81rIEEpnAPuNckPmMYuIjBWRDSKyoYBzUXSYV7ftzVGXN7fMa2K1mNdCrsBbuoI77Te2UqoGQA3A3+iOYF7TK29umVe3FHIF3gCgyih3AXCgsOZQAjCv6cXcpkwhHfh6ABeJSA8ROQvAzQCWh9MsihHzml7MbcoEHkJRSp0UkTsBrAJQBmCeUmpbaC2jWDCv6cXcpk/gaYSBTsYxtcTIMQul1ZjXRNmolOoXxoHizut1112n4zFjxlh1P/rRj3QsYr+Vx40bp+PXXnvNqtu9e3eYTYxSi3nlnZhERI5iB05E5Ch24EREjuIYeIniGHhqOTsGftNNN1nl+fPn67h9+/aBjvnOO+9Y5aVLl1rlhx56KNBxY8AxcCKiNGEHTkTkqEJupScAl156qVUeO3asjnv16mXVXXPNNTpuaGiw6q644godNzY2htlE8qGpqckqL1myxCovWLBAxxs2cJmQYujatatVDjpsYurdu7dV/uyzz6zy4sWLdeziFENegRMROYodOBGRo9iBExE5imPgLSgvL7fK1dXVOjZv4QWAq666yiqfeWb2/9LPP/9cx506dbLqbr31Vh0//PDDvttKwVVWVuq4rKzMqhs/frxV/vDDD3XMMfDiOHr0qFXev/+Lpcurqqqsuk8++UTHBw7YCyqaY+nevPbp08cqv/zyyzoeNGiQVXf48GEfrY4Xr8CJiBzFDpyIyFEcQskwp/y99NJLVt3FF19c9PN7/0Sk4jNXrauoqIixJQQAzz//vFVesWKFju+++26r7uDBgzp+5plnrLqnn35ax7fffnvOc5rTgL13ZZpTgpOKV+BERI5iB05E5Ch24EREjirZMXBzaiBgT93r2LFj1M3B+++/H/k5yb8pU6bo+LnnnrPqzOluFB5z6ubPf/5z368zVxzMNwZuGj58uFWeO3eujtetW+f7OFHiFTgRkaPYgRMROapkh1AGDhxoleMYNjGZq6JR8ph39Hk30aV0qKurs8reOzyTiFfgRESOYgdOROQoduBERI4q2TFw74pyI0eO1HGbNm2suj179rT4PACYPXu2VR4wYICv8//617+2yjt37vT1OiIqjq1bt1plF6aH8gqciMhReTtwEZknIk0istV4rIOI1IpIfeY7VwJyDPOaXsxt6fAzhDIfwFMAzKXCJgNYrZSaJSKTM+VJ4TeveLwrmK1atUrH/fv3t+peeeUVHc+bN8+q8ztkAgAnTpzQ8bJly7LWRWQ+UphXAsDcloy8V+BKqb8B+MDz8DAAp7bpXgDgh+E2i4qNeU0v5rZ0BB0D76iUagSAzPcLwmsSxYh5TS/mNoWKPgtFRMYCSP7K6NQqzGs6Ma9uCdqBHxKRSqVUo4hUAmjK9kSlVA2AGgAQERXwfEVnThVsaGiw6sydQrybGrdGU9MX/01r1qwJfJwiSl1eSfOV2zTkdcGCBfmflBJBh1CWAzi1Hms1gGU5nkvuYF7Ti7lNIT/TCBcB+CeAniLSICJjAMwCMFhE6gEMzpTJIcxrejG3pSPvEIpSamSWqmtCbkukzjzT/qf37dtXx+aC8ADQpUuXUM5ZWVmp4xkzZlh106dP1/Fnn30WyvlySWteibn1/mz7FcNU3oLxTkwiIkexAycichQ7cCIiR4lS0c0UintakrmryqxZ9mc499xzT9TNsQwaNEjHUUwxVEqFtq1M3Hn1q6qqyipv375dx23btvV9nO7du1vlffv2FdSukG1USvUL40Cu5NXL3Ekn305bx48f13Fr3gMxaDGvvAInInIUO3AiIkeV1IYOK1as0PF1110XyjHffvttq9y+fXsdd+vWzfdxRowYoeOE3qXpPHMIDWjdn8zHjh3TcRTTPMm/O+64wypXVPhfKXfmzJlhNydSvAInInIUO3AiIkexAyciclSqx8B79epllVuze47p6NGjOr7//vutut/+9rdZz/Haa6/5Psd3vvMdHXvHajnmGr/HHntMx++9916MLSGvCy+80CqfddZZvl/7jW98Q8cTJ04MdP4333zTKq9duzbQcYLgFTgRkaPYgRMROYodOBGRo1I3Bm7O7f3Wt75l1Yn4u3t8165dVvnaa6/V8d69e3O+dsuWLVmfm2teuLmc7Rln2L9XOQZOabFp0yarbC7lUVtba9WZO2F5mT9Lo0aNCtye0aNHB37tKeat+4C985Z3d6A5c+boOIyfa16BExE5ih04EZGjnB9Cueyyy6zyokWLdNyzZ8+sr/NO/TFXJ9y8ebNV19jY6Ls9hw8f1vF///tfq641t9ZT+L70pS/F3YSS16dPH6tsDqF46+69994IWlS4Tp06ZS17/03m7l4vvPCCVeddlsMPXoETETmKHTgRkaPYgRMROcr5MfCrr77aKuca9zbNnz/fKr/66quBzu+97f3GG2/UsXcaYy7mcqVR7pJUSp588sm4m1Dy6uvrrbJ5K3spmDBhgo6rq6utuny7B7WEV+BERI5iB05E5Cjnh1CC8g61mDvpeKf/mfr1s/cVNYdMAOCBBx4I1J6FCxfq+OTJk4GOQbnV1dVZZXMjaYrGL37xC6uc627LNDJXPDQ3VA6KV+BERI5iB05E5Ki8HbiIVInIGhHZISLbROSuzOMdRKRWROoz3/3vJEqxY15Tq5x5LR2Sb8qaiFQCqFRKbRKRcwBsBPBDALcC+EApNUtEJgOoUEpNynOs0OfHmSsFAsGnA7777rs6/vjjj7M+z7v7R9Dbs70rmA0dOlTHW7duDXTMVuqEBOe1GLp3726V//3vf+s438/BL3/5Sx1PmzYt1HaFbAuA25Ka16uuusoqT5r0RRMGDx4c9ulOc/DgQavsXR3RZH4Wduedd4Zy/iNHjui4ldOFNyql+nkfzHsFrpRqVEptysRHAewA0BnAMACn1kpcgOY3CTmCeU2tE8xr6WjVLBQR6Q7gcgDrAHRUSjUCzZ2BiFyQ5TVjAYwtsJ1URMxrOjGv6ee7AxeRdgBeAnC3UuqI380RlFI1AGoyxwj9T7LVq1dbZXMjYe/wSi7eP6+LYfv27ToePny4Vbdz586in78lSc1rMZh/vgLA+vXrdeydHuq6pOZ1zZo1Vvmtt97S8bPPPmvVee9UzMa7ql+uYdT9+/dbZe+qpK7xNQtFRMrR/GZ4QSn1cubhQ5nx8VPj5E3ZXk/JxLymE/NaOvzMQhEAcwHsUErNNqqWAzj1K7IawLLwm0fFwrymGvNaIvwMoQwAcAuAd0Rkc+ax+wDMAvAHERkDYB+AEUVpIRUL85pO7cC8loy80whDPVkEY6XmWPaGDRusuoqK4k99NTc1fuKJJ6y63//+9zqOe6NipZS/QVEfXBkD95oxY4aOp06dmvO55k5L3l1WWrNjUwRanG4WhKt5Talg0wiJiCiZ2IETETkqdUMopiuvvNIqr1ixQsdt27b1fZxDhw7peOnSpVbd2rVrrfLKlSt1fPToUd/niBqHUOypg97pqOecc07W13mnnO7bty/UdhWIQyjpxCEUIqI0YQdOROQoduBERI5K9Rg4Zccx8NTiGHg6cQyciChN2IETETmKHTgRkaPYgRMROYodOBGRo9iBExE5ih04EZGj2IETETmKHTgRkaPYgRMROYodOBGRo9iBExE5ih04EZGj/OxKH6b/ANgL4LxMnASl2JZuIR+Pec0tyraEmVvmNbfY8xrpcrL6pCIbwlryslBsS3iS1H62JTxJaj/bYuMQChGRo9iBExE5Kq4OvCam87aEbQlPktrPtoQnSe1nWwyxjIETEVHhOIRCROQoduBERI6KtAMXkSEiUiciu0RkcpTnzpx/nog0ichW47EOIlIrIvWZ7xURtKNKRNaIyA4R2SYid8XVljAwr1ZbUpNb5tVqSyLzGlkHLiJlAOYAGAqgF4CRItIrqvNnzAcwxPPYZACrlVIXAVidKRfbSQATlFKXAPgugPGZ/4s42lIQ5vU0qcgt83qaZOZVKRXJF4D+AFYZ5SkApkR1fuO83QFsNcp1ACozcSWAuhjatAzA4CS0hXllbplXd/Ia5RBKZwD7jXJD5rG4dVRKNQJA5vsFUZ5cRLoDuBzAurjbEhDzmoXjuWVes0hSXqPswKWFx0p6DqOItAPwEoC7lVJH4m5PQMxrC1KQW+a1BUnLa5QdeAOAKqPcBcCBCM+fzSERqQSAzPemKE4qIuVofiO8oJR6Oc62FIh59UhJbplXjyTmNcoOfD2Ai0Skh4icBeBmAMsjPH82ywFUZ+JqNI9tFZWICIC5AHYopWbH2ZYQMK+GFOWWeTUkNq8RD/xfD2AngN0ApsbwwcMiAI0ATqD5CmMMgHPR/OlxfeZ7hwja8X00/zm6BcDmzNf1cbSFeWVumVd388pb6YmIHMU7MYmIHMUOnIjIUQV14HHfakvFwbymF3ObMgUM6peh+cONCwGcBeBtAL3yvEbxKxlfzGtqvw6HldsE/Fv4lSevhVyBXwFgl1Jqj1LqUwCLAQwr4HiUDMyr2/bmqGNu3dViXgvpwH3daisiY0Vkg4hsKOBcFB3mNb3y5pZ5dcuZBbzW1622SqkaZLYeEpHT6ilxmNf0yptb5tUthVyBJ/VWWyoM85pezG3KFNKBJ/VWWyoM85pezG3KBB5CUUqdFJE7AaxC86fb85RS20JrGcWCeU0v5jZ9Ir2VnmNqyaGUamk8NBDmNVE2KqX6hXEg5jVRWswr78QkInIUO3AiIkexAyciclQh88CJiJxy6aWXWuVVq1bpuLKyMmvdiBEjrLqPPvqoCK1rPV6BExE5ih04EZGjOIRCRKnStm1bHV9++eVW3ZIlS6zy1772NR17p1Rfe+21Oq6oqLDqOIRCREQFYQdOROQoduBERI7iGDgRpUqPHj10/Ne//tWqE7FXkIhyKZFi4BU4EZGj2IETETmKQyhUss4991wdl5eXW3UHDx4M5RxlZWU6HjhwoFU3d+5cHZtT1gBg165doZyf0o1X4EREjmIHTkTkKHbgRESO4hh4C6ZPn26V7733Xh2fffbZOV+7cOFCHf/ud7+z6tasWVN446hVzHxNmTLFqhs3bpyO27dvb9V16tTJKjc1NQU6/+jRo3X83HPPZX3e/fffb5VvvfXWQOcrRZ07d7bKzzzzTKDjnDx50ipPmDBBx42NjYGOWWy8AicichQ7cCIiR5XsEIp32tgrr7yi46FDh1p1x44d0/HmzZutOu8qZaNGjdKxd2rY1VdfrePt27e3qr3kT5s2bazyk08+qePbbrvN93G+/OUvh9Ie73spm3fffTeU85WixYsXW+Xvfe97WZ9rDnECwNe//nUdr1y50qp76qmnQmhdcfEKnIjIUezAiYgcxQ6ciMhRJTsGPmvWLKs8ZMgQHf/pT3+y6qZOnarjLVu2WHXeMfBJkybp2Jx+CABLly7V8Te/+c1WtpiyMf8vveOhl1xyia9jvPjii1Y56Jh0dXW1VR4+fLiOvSvfmVPTzNvqqXW8GxXnYk7rTANegRMROSpvBy4i80SkSUS2Go91EJFaEanPfK/IdQxKHuY1vZjb0iH5FjQXkYEAPgLwvFLq0sxjjwD4QCk1S0QmA6hQSk3KdZzM62JdPd0c7vjXv/5l1VVVVem4S5cuVl1r7sIypw6++uqrVt2hQ4d07L3TLwZXwtG8eocpHn74YR137NjRqsv1/jancnqnnrVm01pzCKe2ttaqM9vjbcvMmTN1PG3aNN/ny2MjgHsQQm7j/nnNpU+fPjr++9//btWZU0DNuykB4PHHHy9ms4ppo1Kqn/fBvFfgSqm/AfjA8/AwAAsy8QIAPyy0dRQt5jW9mNvSEfRDzI5KqUYAUEo1isgF2Z4oImMBjA14HooW85pevnLLvLql6LNQlFI1AGqAZP9JRq3DvKYT8+qWoB34IRGpzPwmrwQQbKm2iJm3VXft2tWqe+SRR3Qc1spj3g1UHZCYvHqXOnjooYd07B3XNJ1xhj0q+Omnn+r4vvvus+oeffTRQG27+OKLrbI5JdU7Bm+2580337TqQhz39iMxuQ2ib9++Vtlc+sK77MHu3bt17J1WmjZBpxEuB3Dqk6RqAMvCaQ7FjHlNL+Y2hfxMI1wE4J8AeopIg4iMATALwGARqQcwOFMmhzCv6cXclo68QyhKqZFZqq4JuS2hO+ecc6yyebel+ac1YP9JVghzqqJ32tjGjRtDOUcYkp5X7zDJPffco+NcUwM///xzq7xkyRIdv/7661bdZZddlvU43tUizz//fB1777A1Vxz0tq2+vl7Ht9xyS9bzhSnpuQ3iwQcftMreTRxM8+bN03FYm1MnFe/EJCJyFDtwIiJHsQMnInJUqlcj7N+/v1Xu0KGDjv/yl79YdWvXrg10Du8mxxMnTtTxiRMnrDrzlm86nfn5wfjx40M55o9//OMW43y8t2eb0067devm+zjm1EXuuhOcd3qoOUXX/JwBsFf9TDtegRMROYodOBGRo1I9hJLLpk2bQjnOz372M6v87W9/W8feDZD/8Y9/hHLOtDKnAB4/fjzGlgADBw60yvlW7Txl8uTJVtm7UQT5d+WVV+p4wIABVp2Zj0WLFll15p2Y+Xz1q1/Vce/evbM+b/369Vb5k08+8X2OYuIVOBGRo9iBExE5ih04EZGj8u7IE+rJIl6e0rvrzbZt23TsveXaXGHu/fffz1o3Z84cq+6aa+y7k83pTd4dea6//no/zY6EUiq0pRKLkdef/vSnVvmxxx7z2xarHPT9HfQ43vdcU1Pki/61uHNLEHEvJ3vDDTfoePny5Vmf591Y3PzZLisrs+qefvppq3zeeefpeNCgQVnP4d0ce+fOnVmfWyTBduQhIqJkYgdOROQoduBERI5K9TzwAwcOWOWVK1fq2HtbdV1dnY69t8C3a9dOx8eOHbPqjhw5YpW/8pWv6LiUbukNm7kMLAC0adMm0HH+/Oc/69i7RKypbdu2Vtm7K705rupdivj222/XcQxj3iXPXGoYAEaPHq1j77IHQT/b8C43fdNNN+m4NfPOw8YrcCIiR7EDJyJyVKqHULzGjh2btc47HdBk7vDxm9/8xqqbPXu2VTanHPI26uC8QxG/+tWvQj+HOf3M+yeyd5qp+af2G2+8YdU9//zzobeNct/abnrggQd8H3Pv3r1W+eabb9bxhx9+aNWZ74mePXtadcOHD9exuSF61HgFTkTkKHbgRESOYgdOROSokhoD/9///qfjoDuEe2/b7du3r1U2l6k9evRooHNQNG688UYde5cr9TKnFdbU1BStTfSFn/zkJ4FeZ/4MTps2zarbv3+/Vd66dauOq6qqfJ/jjjvu0DHHwImIqNXYgRMROaqkhlCKwXtnl7m6mffuwaTs4kHNzDv28pk+fbqO//jHPxahNRTUgw8+aJXNab8NDQ2+jzNz5kyr7J06aPJOO40Lr8CJiByVtwMXkSoRWSMiO0Rkm4jclXm8g4jUikh95ntFvmNRcjCvqVXOvJYOP1fgJwFMUEpdAuC7AMaLSC8AkwGsVkpdBGB1pkzuYF7Ti3ktEXnHwJVSjQAaM/FREdkBoDOAYQD+L/O0BQDeADCpKK1MkJMnT1pl71RBc1ph+/btrbpDhw4VrV2tVYp5nThxolX+wQ9+kPW55iqGAPDss88WpU1FcEIptQkonbw+/vjjVtm7QqjJXOoCsG+lHzFiRNbXvffee1Z5wYIFrWhh8bTqQ0wR6Q7gcgDrAHTMdAJQSjWKyAVZXjMWQPZFSCh2zGs6Ma/p57sDF5F2AF4CcLdS6oh39kU2SqkaADWZY8S6xx6djnlNJ+a1NPjqwEWkHM1vhheUUi9nHj4kIpWZ3+aVAEpiJXvvwv/eBeNdUgp5NTcZHjdunFVXXl6e9XXeqWnHjx8Pt2FFlJa8mit95trUulevXlbZuxmHyTv9r0ePHlmfe/jwYR2PHDnSqtu8eXPW10XJzywUATAXwA6llLl26nIA1Zm4GsCy8JtHxcK8phrzWiL8XIEPAHALgHdEZHPmsfsAzALwBxEZA2AfgOyfAFASMa/p1A7Ma8nwMwvlTQDZBtCy74JAica8ptZHSinmtUTwVvqQbdy4UcfeHT4oeubt8l27drXqcm1ou2HDhqK1ifzZs2ePr+e99dZbvo95xhn2qLG589LHH39s1Q0bNkzH69at832OKPFWeiIiR7EDJyJyFIdQWmnUqFFW2Tu/duXKlTr+9NNPI2kTfcG74cb48eN9vc672S3Fz/xZKisri7ElycUrcCIiR7EDJyJyFDtwIiJHcQzch7PPPlvH3jFw71Q0cxohRc97G7W5we0NN9yQ9XUvvvhi0dpEVCy8AicichQ7cCIiR3EIxQdzEfjevXtbdd67t8ypTxS9EydOWOXXX39dx94hlO3bt+v40UcfLW7DiIqAV+BERI5iB05E5Ch24EREjpJcK7KFfjJHt2gyV7FbuHChVTdjxgyrXFtbG0mbCpVjydFWczWvKbVRKdUvjAMxr4nSYl55BU5E5Ch24EREjuIQSoniEEpqcQglnTiEQkSUJuzAiYgcxQ6ciMhRUd9K/x8AewGcl4mToBTb0i3k4zGvuUXZljBzy7zmFnteI/0QU59UZENYH7QUim0JT5Laz7aEJ0ntZ1tsHEIhInIUO3AiIkfF1YHXxHTelrAt4UlS+9mW8CSp/WyLIZYxcCIiKhyHUIiIHMUOnIjIUZF24CIyRETqRGSXiEyO8tyZ888TkSYR2Wo81kFEakWkPvO9IoJ2VInIGhHZISLbROSuuNoSBubVaktqcsu8Wm1JZF4j68BFpAzAHABDAfQCMFJEekV1/oz5AIZ4HpsMYLVS6iIAqzPlYjsJYIJS6hIA3wUwPvN/EUdbCsK8niYVuWVeT5PMvCqlIvkC0B/AKqM8BcCUqM5vnLc7gK1GuQ5AZSauBFAXQ5uWARichLYwr8wt8+pOXqMcQukMYL9Rbsg8FreOSqlGAMh8vyDKk4tIdwCXA1gXd1sCYl6zcDy3zGsWScprlB14S+tPl/QcRhFpB+AlAHcrpY7E3Z6AmNcWpCC3zGsLkpbXKDvwBgBVRrkLgAMRnj+bQyJSCQCZ701RnFREytH8RnhBKfVynG0pEPPqkZLcMq8eScxrlB34egAXiUgPETkLwM0Alkd4/myWA6jOxNVoHtsqKhERAHMB7FBKzY6zLSFgXg0pyi3zakhsXiMe+L8ewE4AuwFMjeGDh0UAGgGcQPMVxhgA56L50+P6zPcOEbTj+2j+c3QLgM2Zr+vjaAvzytwyr+7mlbfSExE5indiEhE5ih04EZGj2IETETmKHTgRkaPYgRMROYodOBGRo9iBExE56v8BM0L+ur1+1PMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.imshow(features[i][0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Multi-Layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected neural network with one hidden layer\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.l1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        # no activation and no softmax at the end\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNet(\n",
      "  (l1): Linear(in_features=784, out_features=100, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (l2): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create our model\n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 & 6. Train in batches and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # origin shape: [100, 1, 28, 28]\n",
    "        # resized: [100, 784]\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the 10000 test images: {acc} %')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
